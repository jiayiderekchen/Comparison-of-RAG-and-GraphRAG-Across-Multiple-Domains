{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "W4tK8ykGv96F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fcff7a8-f87d-455f-e686-cc0164e14359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install datasets sentence-transformers networkx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "\n",
        "def download_squad(dataset_type=\"train\", save_path=\"squad\"):\n",
        "    \"\"\"\n",
        "    Download the SQuAD dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset_type (str): \"train\" or \"dev\" (validation set).\n",
        "        save_path (str): Directory to save the dataset.\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the downloaded dataset file.\n",
        "    \"\"\"\n",
        "    base_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/\"\n",
        "    file_name = f\"{dataset_type}-v2.0.json\"\n",
        "    url = base_url + file_name\n",
        "\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # File path to save\n",
        "    file_path = os.path.join(save_path, file_name)\n",
        "\n",
        "    # Download the file\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Downloading {dataset_type} dataset...\")\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            print(f\"{dataset_type} dataset downloaded successfully and saved to {file_path}\")\n",
        "        else:\n",
        "            raise Exception(f\"Failed to download {dataset_type} dataset. HTTP Status: {response.status_code}\")\n",
        "    else:\n",
        "        print(f\"{dataset_type} dataset already exists at {file_path}\")\n",
        "\n",
        "    return file_path\n",
        "\n",
        "def load_squad_data(filepath):\n",
        "    \"\"\"\n",
        "    Load the SQuAD dataset and prepare documents, queries, and relevant documents.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): Path to the SQuAD JSON file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: documents, queries, relevant_docs\n",
        "    \"\"\"\n",
        "    with open(filepath, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    documents = []\n",
        "    queries = []\n",
        "    relevant_docs = []\n",
        "\n",
        "    for topic in data['data']:\n",
        "        for paragraph in topic['paragraphs']:\n",
        "            context = paragraph['context']\n",
        "            for qa in paragraph['qas']:\n",
        "                queries.append(qa['question'])\n",
        "                relevant_docs.append(context)  # Map query to its context\n",
        "                documents.append(context)  # Repeat document for each query\n",
        "\n",
        "    return documents, queries, relevant_docs\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Step 1: Download the SQuAD train dataset\n",
        "    squad_train_path = download_squad(dataset_type=\"train\")\n",
        "\n",
        "    # Step 2: Load the dataset\n",
        "    documents_squad, queries_squad, relevant_docs_squad = load_squad_data(squad_train_path)\n",
        "\n",
        "    # Step 3: Print some examples to verify\n",
        "    print(f\"Number of documents: {len(documents_squad)}\")\n",
        "    print(f\"Number of queries: {len(queries_squad)}\")\n",
        "    print(f\"Number of relevant docs: {len(relevant_docs_squad)}\")\n",
        "    print(\"\\nSample Query and Relevant Doc:\")\n",
        "    print(f\"Query: {queries_squad[0]}\")\n",
        "    print(f\"Relevant Doc: {relevant_docs_squad[0]}\")"
      ],
      "metadata": {
        "id": "T1lmtXaDrKjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1e8fe4-ce24-484b-9b82-311536fc21ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train dataset...\n",
            "train dataset downloaded successfully and saved to squad/train-v2.0.json\n",
            "Number of documents: 130319\n",
            "Number of queries: 130319\n",
            "Number of relevant docs: 130319\n",
            "\n",
            "Sample Query and Relevant Doc:\n",
            "Query: When did Beyonce start becoming popular?\n",
            "Relevant Doc: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def download_pubmedqa_from_github(save_path=\"pubmedqa\"):\n",
        "    \"\"\"\n",
        "    Download PubMedQA dataset files from GitHub.\n",
        "\n",
        "    Args:\n",
        "        save_path (str): Directory to save the dataset.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Paths to the downloaded dataset files.\n",
        "    \"\"\"\n",
        "    base_url = \"https://raw.githubusercontent.com/pubmedqa/pubmedqa/master/data/\"\n",
        "    files = [\"ori_pqal.json\", \"test_ground_truth.json\"]\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    downloaded_files = []\n",
        "    for file_name in files:\n",
        "        url = base_url + file_name\n",
        "        file_path = os.path.join(save_path, file_name)\n",
        "\n",
        "        # Download the file\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Downloading {file_name}...\")\n",
        "            response = requests.get(url)\n",
        "            if response.status_code == 200:\n",
        "                with open(file_path, \"wb\") as f:\n",
        "                    f.write(response.content)\n",
        "                print(f\"{file_name} downloaded successfully and saved to {file_path}\")\n",
        "            else:\n",
        "                raise Exception(f\"Failed to download {file_name}. HTTP Status: {response.status_code}\")\n",
        "        else:\n",
        "            print(f\"{file_name} already exists at {file_path}\")\n",
        "\n",
        "        downloaded_files.append(file_path)\n",
        "\n",
        "    return downloaded_files\n",
        "\n",
        "\n",
        "def load_pubmedqa_data(filepath):\n",
        "    \"\"\"\n",
        "    Load PubMedQA dataset from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): Path to the PubMedQA JSON file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: documents, queries, relevant_docs\n",
        "    \"\"\"\n",
        "    with open(filepath, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    long_answers = []\n",
        "    queries = []\n",
        "    relevant_docs = []\n",
        "\n",
        "    for id_, entry in data.items():\n",
        "        question = entry.get('QUESTION', '')\n",
        "        context = \" \".join(entry.get('CONTEXTS', []))\n",
        "        long_answer = entry.get('LONG_ANSWER', '')\n",
        "\n",
        "        if question:\n",
        "            # Add contexts and long answers separately\n",
        "            contexts.append(context)\n",
        "            long_answers.append(long_answer)\n",
        "            queries.append(question)\n",
        "            relevant_docs.append(long_answer)  # Use long answer as the relevant document\n",
        "\n",
        "    # Combine contexts and long answers into one retrieval pool\n",
        "    documents = contexts + long_answers\n",
        "    return documents, queries, relevant_docs\n",
        "\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Step 1: Download the PubMedQA dataset\n",
        "    pubmedqa_files = download_pubmedqa_from_github()\n",
        "\n",
        "    # Step 2: Load the dataset\n",
        "    ori_pqal_path = pubmedqa_files[0]\n",
        "    documents_pubmedqa, queries_pubmedqa, relevant_docs_pubmedqa = load_pubmedqa_data(ori_pqal_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNyxIt66toLx",
        "outputId": "c8835456-0f64-4350-ff99-48f79e4b192c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ori_pqal.json...\n",
            "ori_pqal.json downloaded successfully and saved to pubmedqa/ori_pqal.json\n",
            "Downloading test_ground_truth.json...\n",
            "test_ground_truth.json downloaded successfully and saved to pubmedqa/test_ground_truth.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_arxiv_data(filepath):\n",
        "    \"\"\"\n",
        "    Load and preprocess the arXiv dataset.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): Path to the JSON dataset file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: documents, queries, relevant_docs\n",
        "    \"\"\"\n",
        "    documents, queries, relevant_docs = [], [], []\n",
        "\n",
        "    with open(filepath, 'r') as f:\n",
        "        try:\n",
        "            # Load the entire JSON array\n",
        "            records = json.load(f)\n",
        "            for record in records:\n",
        "                documents.append(record.get(\"abstract\", \"\"))\n",
        "                queries.append(record.get(\"title\", \"\"))\n",
        "                relevant_docs.append(record.get(\"abstract\", \"\"))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON: {e}\")\n",
        "            return [], [], []\n",
        "\n",
        "    return documents, queries, relevant_docs"
      ],
      "metadata": {
        "id": "S5J4YXTxycMG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import networkx as nx\n",
        "from community import community_louvain  # For Louvain community detection\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import time\n",
        "\n",
        "@dataclass\n",
        "class RetrievalResult:\n",
        "    \"\"\"Data class to store retrieval results\"\"\"\n",
        "    retrieved_docs: List[str]\n",
        "    relevance_scores: List[float]\n",
        "    retrieval_time: float\n",
        "\n",
        "def encode_with_batches(encoder, texts, batch_size=32) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Encode texts in batches for efficiency.\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i + batch_size]\n",
        "        embeddings.extend(encoder.encode(batch, convert_to_tensor=False))\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "class BaseRAG:\n",
        "    \"\"\"Base RAG implementation using simple vector similarity\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
        "        self.encoder = SentenceTransformer(model_name)\n",
        "        self.documents = []\n",
        "        self.embeddings = None\n",
        "\n",
        "    def add_documents(self, documents: List[str], batch_size: int = 32) -> None:\n",
        "        self.documents = documents\n",
        "        self.embeddings = encode_with_batches(self.encoder, documents, batch_size=batch_size)\n",
        "\n",
        "    def retrieve(self, query: str, k: int = 3) -> RetrievalResult:\n",
        "        start_time = time.time()\n",
        "        query_embedding = self.encoder.encode(query)\n",
        "        similarities = cosine_similarity(\n",
        "            query_embedding.reshape(1, -1),\n",
        "            self.embeddings\n",
        "        )[0]\n",
        "        top_indices = np.argsort(similarities)[-k:][::-1]\n",
        "        retrieval_time = time.time() - start_time\n",
        "        return RetrievalResult(\n",
        "            retrieved_docs=[self.documents[i] for i in top_indices],\n",
        "            relevance_scores=similarities[top_indices].tolist(),\n",
        "            retrieval_time=retrieval_time\n",
        "        )\n",
        "\n",
        "class GraphRAG(BaseRAG):\n",
        "    \"\"\"Graph-enhanced RAG implementation with k-NN graph construction and community detection.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
        "        super().__init__(model_name)\n",
        "        self.graph = nx.Graph()\n",
        "        self.node_communities = {}\n",
        "\n",
        "    def add_documents(self, documents: List[str], batch_size: int = 32, k_neighbors: int = 5, similarity_threshold: float = 0.3):\n",
        "        \"\"\"\n",
        "        Add documents to the retriever and construct a k-NN graph.\n",
        "        \"\"\"\n",
        "        print(\"Encoding documents...\")\n",
        "        super().add_documents(documents, batch_size=batch_size)\n",
        "\n",
        "        similarity_matrix = cosine_similarity(self.embeddings)\n",
        "        print(\"Building graph...\")\n",
        "\n",
        "        for i in range(len(documents)):\n",
        "            self.graph.add_node(i, content=documents[i])\n",
        "            neighbors = np.argsort(similarity_matrix[i])[-(k_neighbors + 1):-1][::-1]\n",
        "            for j in neighbors:\n",
        "                if similarity_matrix[i, j] > similarity_threshold:\n",
        "                    self.graph.add_edge(i, j, weight=similarity_matrix[i, j])\n",
        "\n",
        "        print(\"Detecting communities...\")\n",
        "        self.node_communities = community_louvain.best_partition(self.graph, weight='weight')\n",
        "\n",
        "        density = nx.density(self.graph)\n",
        "        num_components = nx.number_connected_components(self.graph)\n",
        "        num_communities = len(set(self.node_communities.values()))\n",
        "        print(f\"Graph constructed with density: {density:.4f}, {num_components} connected components, \"\n",
        "              f\"and {num_communities} communities.\")\n",
        "\n",
        "    def retrieve(self, query: str, k: int = 5, sim_weight: float = 0.6, cluster_weight: float = 0.7) -> RetrievalResult:\n",
        "        \"\"\"\n",
        "        Retrieve top-k documents based on similarity, PageRank, and community information.\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "        query_embedding = self.encoder.encode(query)\n",
        "        similarities = cosine_similarity(query_embedding.reshape(1, -1), self.embeddings)[0]\n",
        "\n",
        "        pagerank_scores = nx.pagerank(self.graph)\n",
        "        query_top_index = np.argmax(similarities)\n",
        "        query_cluster = self.node_communities.get(query_top_index, -1)\n",
        "\n",
        "        final_scores = []\n",
        "        cluster_size = sum(1 for c in self.node_communities.values() if c == query_cluster)\n",
        "        for i in range(len(self.documents)):\n",
        "            cluster_bonus = cluster_weight / cluster_size if self.node_communities.get(i) == query_cluster else 0.0\n",
        "            score = sim_weight * similarities[i] + (1 - sim_weight) * pagerank_scores[i] + cluster_bonus\n",
        "            final_scores.append(score)\n",
        "\n",
        "        final_scores = np.array(final_scores)\n",
        "        top_indices = np.argsort(final_scores)[-k:][::-1]\n",
        "        retrieval_time = time.time() - start_time\n",
        "        return RetrievalResult(\n",
        "            retrieved_docs=[self.documents[i] for i in top_indices],\n",
        "            relevance_scores=final_scores[top_indices].tolist(),\n",
        "            retrieval_time=retrieval_time\n",
        "        )"
      ],
      "metadata": {
        "id": "FDh0X3FYt6OO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all datasets"
      ],
      "metadata": {
        "id": "ti6saMRFrk6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_retrievers(documents, queries, relevant_docs, k):\n",
        "    \"\"\"\n",
        "    Evaluate BaseRAG and GraphRAG retrievers on the given dataset.\n",
        "\n",
        "    Args:\n",
        "        documents (List[str]): List of document texts.\n",
        "        queries (List[str]): List of query texts.\n",
        "        relevant_docs (List[str]): List of relevant documents for each query.\n",
        "        k (int): Number of top documents to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Dict[str, float]]: Evaluation metrics for BaseRAG and GraphRAG.\n",
        "    \"\"\"\n",
        "    # Initialize retrievers\n",
        "    base_rag = BaseRAG()\n",
        "    graph_rag = GraphRAG()\n",
        "\n",
        "    # base_rag = BaseRAG(model_name=\"multi-qa-mpnet-base-dot-v1\")\n",
        "    # graph_rag = GraphRAG(model_name=\"multi-qa-mpnet-base-dot-v1\")\n",
        "\n",
        "    # Add documents to retrievers\n",
        "    base_rag.add_documents(documents)\n",
        "    graph_rag.add_documents(documents)\n",
        "\n",
        "    # Initialize metrics\n",
        "    metrics = {\n",
        "        'BaseRAG': {'hits': 0, 'mrr': 0.0, 'precision': 0.0, 'recall': 0.0, 'avg_time': 0.0},\n",
        "        'GraphRAG': {'hits': 0, 'mrr': 0.0, 'precision': 0.0, 'recall': 0.0, 'avg_time': 0.0}\n",
        "    }\n",
        "\n",
        "    # Evaluate queries\n",
        "    for query, relevant in zip(queries, relevant_docs):\n",
        "        relevant_set = {relevant}\n",
        "\n",
        "        for retriever_name, retriever in [('BaseRAG', base_rag), ('GraphRAG', graph_rag)]:\n",
        "            # Retrieve results\n",
        "            result = retriever.retrieve(query, k)\n",
        "            retrieved_docs = result.retrieved_docs[:k]\n",
        "            retrieved_set = set(retrieved_docs)\n",
        "\n",
        "            # Calculate metrics\n",
        "            hits = int(bool(relevant_set.intersection(retrieved_set)))\n",
        "            rank = (\n",
        "                retrieved_docs.index(next(iter(relevant_set.intersection(retrieved_set)))) + 1\n",
        "                if relevant_set.intersection(retrieved_set)\n",
        "                else 0\n",
        "            )\n",
        "            precision = len(relevant_set.intersection(retrieved_set)) / k\n",
        "            # recall = len(relevant_set.intersection(retrieved_set)) / len(relevant_set)  # Corrected\n",
        "            recall = len(relevant_set.intersection(retrieved_set)) / len(relevant_set) if len(relevant_set) > 0 else 0\n",
        "\n",
        "            # Update metrics\n",
        "            metrics[retriever_name]['hits'] += hits\n",
        "            metrics[retriever_name]['mrr'] += 1.0 / rank if rank else 0.0\n",
        "            metrics[retriever_name]['precision'] += precision\n",
        "            metrics[retriever_name]['recall'] += recall\n",
        "            metrics[retriever_name]['avg_time'] += result.retrieval_time\n",
        "\n",
        "    # Normalize metrics\n",
        "    num_queries = len(queries)\n",
        "    for retriever_name in metrics:\n",
        "        for metric in metrics[retriever_name]:\n",
        "            metrics[retriever_name][metric] /= num_queries\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def reduce_dataset(documents, queries, relevant_docs, sample_size, dataset_name=\"pubmed\"):\n",
        "    \"\"\"\n",
        "    Reduce the size of the dataset for faster benchmarking.\n",
        "\n",
        "    Args:\n",
        "        documents (List[str]): List of all documents.\n",
        "        queries (List[str]): List of all queries.\n",
        "        relevant_docs (List[str]): List of all relevant documents.\n",
        "        sample_size (int): Number of samples to take.\n",
        "        dataset_name (str): Name of the dataset (\"pubmed\" or \"squad\").\n",
        "\n",
        "    Returns:\n",
        "        tuple: Reduced documents, queries, and relevant_docs.\n",
        "    \"\"\"\n",
        "    print(f\"Documents: {len(documents)}, Queries: {len(queries)}, Relevant Docs: {len(relevant_docs)}\")\n",
        "\n",
        "    if dataset_name == \"pubmed\":\n",
        "        if len(queries) != len(relevant_docs):\n",
        "            raise ValueError(\"Queries and relevant_docs lists must have the same size.\")\n",
        "\n",
        "        sample_size = min(sample_size, len(queries))  # Ensure we don't sample more than available\n",
        "        indices = np.random.choice(len(queries), size=sample_size, replace=False)\n",
        "\n",
        "        queries_subset = [queries[i] for i in indices]\n",
        "        relevant_docs_subset = [relevant_docs[i] for i in indices]\n",
        "\n",
        "        # Adjust the retrieval pool (documents) based on the selected subset\n",
        "        retrieval_pool = [documents[i] for i in indices] + [documents[i + len(queries)] for i in indices]\n",
        "\n",
        "        return retrieval_pool, queries_subset, relevant_docs_subset\n",
        "\n",
        "    elif dataset_name == \"squad\":\n",
        "        if not (len(documents) == len(queries) == len(relevant_docs)):\n",
        "            raise ValueError(\"Documents, queries, and relevant_docs lists must have the same size.\")\n",
        "\n",
        "        sample_size = min(sample_size, len(documents), len(queries), len(relevant_docs))\n",
        "        indices = list(range(len(queries)))\n",
        "        np.random.shuffle(indices)  # Shuffle indices\n",
        "        indices = indices[:sample_size]\n",
        "\n",
        "        documents_subset = [documents[i] for i in indices]\n",
        "        queries_subset = [queries[i] for i in indices]\n",
        "        relevant_docs_subset = [relevant_docs[i] for i in indices]\n",
        "\n",
        "        return documents_subset, queries_subset, relevant_docs_subset\n",
        "\n",
        "    elif dataset_name == \"arxiv\":\n",
        "        if len(queries) != len(relevant_docs):\n",
        "            raise ValueError(\"Queries and relevant_docs lists must have the same size.\")\n",
        "\n",
        "        sample_size = min(sample_size, len(queries))  # Ensure we don't sample more than available\n",
        "        indices = np.random.choice(len(queries), size=sample_size, replace=False)\n",
        "\n",
        "        # Create subsets for arXiv dataset\n",
        "        documents_subset = [documents[i] for i in indices]\n",
        "        queries_subset = [queries[i] for i in indices]\n",
        "        relevant_docs_subset = [relevant_docs[i] for i in indices]\n",
        "\n",
        "        # print(f\"Sampled Size: {len(documents_subset)}\")  # Debug print\n",
        "        return documents_subset, queries_subset, relevant_docs_subset\n",
        "\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset_name: {dataset_name}\")\n",
        "\n",
        "\n",
        "\n",
        "def run_benchmarks():\n",
        "    \"\"\"\n",
        "    Run benchmarks on SQuAD and PubMedQA datasets.\n",
        "    \"\"\"\n",
        "    # Load and evaluate SQuAD dataset\n",
        "    print(\"Loading SQuAD dataset...\")\n",
        "    squad_path = \"squad/train-v2.0.json\"\n",
        "    documents_squad, queries_squad, relevant_docs_squad = load_squad_data(squad_path)\n",
        "    retrieval_pool, queries_subset, relevant_docs_subset = reduce_dataset(\n",
        "        documents_squad, queries_squad, relevant_docs_squad, sample_size=3500, dataset_name=\"squad\"\n",
        "    )\n",
        "    print(\"Running SQuAD benchmark...\")\n",
        "    metrics_squad = evaluate_retrievers(retrieval_pool, queries_subset, relevant_docs_subset, k=7)\n",
        "\n",
        "    # Load and evaluate PubMedQA dataset\n",
        "    print(\"Loading PubMedQA dataset...\")\n",
        "    pubmedqa_path = \"pubmedqa/ori_pqal.json\"\n",
        "    documents_pubmedqa, queries_pubmedqa, relevant_docs_pubmedqa = load_pubmedqa_data(pubmedqa_path)\n",
        "    retrieval_pool, queries_subset, relevant_docs_subset = reduce_dataset(\n",
        "        documents_pubmedqa, queries_pubmedqa, relevant_docs_pubmedqa, sample_size=3500, dataset_name=\"pubmed\"\n",
        "    )\n",
        "    print(\"Running PubMedQA benchmark...\")\n",
        "    metrics_pubmedqa = evaluate_retrievers(retrieval_pool, queries_subset, relevant_docs_subset, k=7)\n",
        "\n",
        "    # Load and evaluate arXiv dataset\n",
        "    print(\"Loading arXiv dataset...\")\n",
        "    arxiv_path = \"/content/arxiv/arxiv-metadata-subset.json\"\n",
        "    documents, queries, relevant_docs = load_arxiv_data(arxiv_path)\n",
        "    reduced_documents, reduced_queries, reduced_relevant_docs = reduce_dataset(\n",
        "        documents, queries, relevant_docs, sample_size=3500, dataset_name=\"arxiv\"\n",
        "    )\n",
        "    print(\"Running arXiv benchmark...\")\n",
        "    metrics_arxiv = evaluate_retrievers(reduced_documents, reduced_queries, reduced_relevant_docs, k=7)\n",
        "\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nBenchmark Results:\")\n",
        "    for dataset_name, metrics in [\n",
        "        ('SQuAD', metrics_squad),\n",
        "        ('PubMedQA', metrics_pubmedqa),\n",
        "        ('arXiv', metrics_arxiv)\n",
        "    ]:\n",
        "        print(f\"\\nDataset: {dataset_name}\")\n",
        "        for retriever_name, retriever_metrics in metrics.items():\n",
        "            print(f\"  {retriever_name}:\")\n",
        "            for metric, value in retriever_metrics.items():\n",
        "                print(f\"    {metric}: {value:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "n7WiVOJMrkzG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_benchmarks()"
      ],
      "metadata": {
        "id": "10a1qafTr1gX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae60809-454a-4530-e208-a371c0103739"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading SQuAD dataset...\n",
            "Documents: 130319, Queries: 130319, Relevant Docs: 130319\n",
            "Running SQuAD benchmark...\n",
            "Encoding documents...\n",
            "Building graph...\n",
            "Detecting communities...\n",
            "Graph constructed with density: 0.0020, 3 connected components, and 41 communities.\n",
            "Loading PubMedQA dataset...\n",
            "Documents: 2000, Queries: 1000, Relevant Docs: 1000\n",
            "Running PubMedQA benchmark...\n",
            "Encoding documents...\n",
            "Building graph...\n",
            "Detecting communities...\n",
            "Graph constructed with density: 0.0035, 1 connected components, and 21 communities.\n",
            "Loading arXiv dataset...\n",
            "Documents: 100000, Queries: 100000, Relevant Docs: 100000\n",
            "Running arXiv benchmark...\n",
            "Encoding documents...\n",
            "Building graph...\n",
            "Detecting communities...\n",
            "Graph constructed with density: 0.0021, 11 connected components, and 25 communities.\n",
            "\n",
            "Benchmark Results:\n",
            "\n",
            "Dataset: SQuAD\n",
            "  BaseRAG:\n",
            "    hits: 0.9106\n",
            "    mrr: 0.7972\n",
            "    precision: 0.1301\n",
            "    recall: 0.9106\n",
            "    avg_time: 0.0172\n",
            "  GraphRAG:\n",
            "    hits: 0.9106\n",
            "    mrr: 0.7970\n",
            "    precision: 0.1301\n",
            "    recall: 0.9106\n",
            "    avg_time: 0.1032\n",
            "\n",
            "Dataset: PubMedQA\n",
            "  BaseRAG:\n",
            "    hits: 0.9060\n",
            "    mrr: 0.6437\n",
            "    precision: 0.1294\n",
            "    recall: 0.9060\n",
            "    avg_time: 0.0152\n",
            "  GraphRAG:\n",
            "    hits: 0.9100\n",
            "    mrr: 0.6438\n",
            "    precision: 0.1300\n",
            "    recall: 0.9100\n",
            "    avg_time: 0.0598\n",
            "\n",
            "Dataset: arXiv\n",
            "  BaseRAG:\n",
            "    hits: 0.9637\n",
            "    mrr: 0.9055\n",
            "    precision: 0.1377\n",
            "    recall: 0.9637\n",
            "    avg_time: 0.0171\n",
            "  GraphRAG:\n",
            "    hits: 0.9631\n",
            "    mrr: 0.9054\n",
            "    precision: 0.1376\n",
            "    recall: 0.9631\n",
            "    avg_time: 0.1052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single dataset"
      ],
      "metadata": {
        "id": "ca8kGt9Erhjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_retrievers(documents, queries, relevant_docs, k):\n",
        "    \"\"\"\n",
        "    Evaluate BaseRAG and GraphRAG retrievers on the given dataset.\n",
        "\n",
        "    Args:\n",
        "        documents (List[str]): List of document texts.\n",
        "        queries (List[str]): List of query texts.\n",
        "        relevant_docs (List[str]): List of relevant documents for each query.\n",
        "        k (int): Number of top documents to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Dict[str, float]]: Evaluation metrics for BaseRAG and GraphRAG.\n",
        "    \"\"\"\n",
        "    # Initialize retrievers\n",
        "    base_rag = BaseRAG()\n",
        "    graph_rag = GraphRAG()\n",
        "\n",
        "    # base_rag = BaseRAG(model_name=\"multi-qa-mpnet-base-dot-v1\")\n",
        "    # graph_rag = GraphRAG(model_name=\"multi-qa-mpnet-base-dot-v1\")\n",
        "\n",
        "    # Add documents to retrievers\n",
        "    base_rag.add_documents(documents)\n",
        "    graph_rag.add_documents(documents)\n",
        "\n",
        "    # Initialize metrics\n",
        "    metrics = {\n",
        "        'BaseRAG': {'hits': 0, 'mrr': 0.0, 'precision': 0.0, 'recall': 0.0, 'avg_time': 0.0},\n",
        "        'GraphRAG': {'hits': 0, 'mrr': 0.0, 'precision': 0.0, 'recall': 0.0, 'avg_time': 0.0}\n",
        "    }\n",
        "\n",
        "    # Evaluate queries\n",
        "    for query, relevant in zip(queries, relevant_docs):\n",
        "        relevant_set = {relevant}\n",
        "\n",
        "        for retriever_name, retriever in [('BaseRAG', base_rag), ('GraphRAG', graph_rag)]:\n",
        "            # Retrieve results\n",
        "            result = retriever.retrieve(query, k)\n",
        "            retrieved_docs = result.retrieved_docs[:k]\n",
        "            retrieved_set = set(retrieved_docs)\n",
        "\n",
        "            # Calculate metrics\n",
        "            hits = int(bool(relevant_set.intersection(retrieved_set)))\n",
        "            rank = (\n",
        "                retrieved_docs.index(next(iter(relevant_set.intersection(retrieved_set)))) + 1\n",
        "                if relevant_set.intersection(retrieved_set)\n",
        "                else 0\n",
        "            )\n",
        "            precision = len(relevant_set.intersection(retrieved_set)) / k\n",
        "            # recall = len(relevant_set.intersection(retrieved_set)) / len(relevant_set)  # Corrected\n",
        "            recall = len(relevant_set.intersection(retrieved_set)) / len(relevant_set) if len(relevant_set) > 0 else 0\n",
        "\n",
        "            # Update metrics\n",
        "            metrics[retriever_name]['hits'] += hits\n",
        "            metrics[retriever_name]['mrr'] += 1.0 / rank if rank else 0.0\n",
        "            metrics[retriever_name]['precision'] += precision\n",
        "            metrics[retriever_name]['recall'] += recall\n",
        "            metrics[retriever_name]['avg_time'] += result.retrieval_time\n",
        "\n",
        "    # Normalize metrics\n",
        "    num_queries = len(queries)\n",
        "    for retriever_name in metrics:\n",
        "        for metric in metrics[retriever_name]:\n",
        "            metrics[retriever_name][metric] /= num_queries\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def reduce_dataset(documents, queries, relevant_docs, sample_size, dataset_name=\"pubmed\"):\n",
        "    \"\"\"\n",
        "    Reduce the size of the dataset for faster benchmarking.\n",
        "\n",
        "    Args:\n",
        "        documents (List[str]): List of all documents.\n",
        "        queries (List[str]): List of all queries.\n",
        "        relevant_docs (List[str]): List of all relevant documents.\n",
        "        sample_size (int): Number of samples to take.\n",
        "        dataset_name (str): Name of the dataset (\"pubmed\" or \"squad\").\n",
        "\n",
        "    Returns:\n",
        "        tuple: Reduced documents, queries, and relevant_docs.\n",
        "    \"\"\"\n",
        "    print(f\"Documents: {len(documents)}, Queries: {len(queries)}, Relevant Docs: {len(relevant_docs)}\")\n",
        "\n",
        "    if dataset_name == \"pubmed\":\n",
        "        if len(queries) != len(relevant_docs):\n",
        "            raise ValueError(\"Queries and relevant_docs lists must have the same size.\")\n",
        "\n",
        "        sample_size = min(sample_size, len(queries))  # Ensure we don't sample more than available\n",
        "        indices = np.random.choice(len(queries), size=sample_size, replace=False)\n",
        "\n",
        "        queries_subset = [queries[i] for i in indices]\n",
        "        relevant_docs_subset = [relevant_docs[i] for i in indices]\n",
        "\n",
        "        # Adjust the retrieval pool (documents) based on the selected subset\n",
        "        retrieval_pool = [documents[i] for i in indices] + [documents[i + len(queries)] for i in indices]\n",
        "\n",
        "        return retrieval_pool, queries_subset, relevant_docs_subset\n",
        "\n",
        "    elif dataset_name == \"squad\":\n",
        "        if not (len(documents) == len(queries) == len(relevant_docs)):\n",
        "            raise ValueError(\"Documents, queries, and relevant_docs lists must have the same size.\")\n",
        "\n",
        "        sample_size = min(sample_size, len(documents), len(queries), len(relevant_docs))\n",
        "        indices = list(range(len(queries)))\n",
        "        np.random.shuffle(indices)  # Shuffle indices\n",
        "        indices = indices[:sample_size]\n",
        "\n",
        "        documents_subset = [documents[i] for i in indices]\n",
        "        queries_subset = [queries[i] for i in indices]\n",
        "        relevant_docs_subset = [relevant_docs[i] for i in indices]\n",
        "\n",
        "        return documents_subset, queries_subset, relevant_docs_subset\n",
        "\n",
        "    elif dataset_name == \"arxiv\":\n",
        "        if len(queries) != len(relevant_docs):\n",
        "            raise ValueError(\"Queries and relevant_docs lists must have the same size.\")\n",
        "\n",
        "        sample_size = min(sample_size, len(queries))  # Ensure we don't sample more than available\n",
        "        indices = np.random.choice(len(queries), size=sample_size, replace=False)\n",
        "\n",
        "        # Create subsets for arXiv dataset\n",
        "        documents_subset = [documents[i] for i in indices]\n",
        "        queries_subset = [queries[i] for i in indices]\n",
        "        relevant_docs_subset = [relevant_docs[i] for i in indices]\n",
        "\n",
        "        # print(f\"Sampled Size: {len(documents_subset)}\")  # Debug print\n",
        "        return documents_subset, queries_subset, relevant_docs_subset\n",
        "\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset_name: {dataset_name}\")\n"
      ],
      "metadata": {
        "id": "lhEqCiNGt4bA"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_benchmarks_single(dataset_name: str, sample_size: int, k: int):\n",
        "    \"\"\"\n",
        "    Run benchmarks on the specified dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset_name (str): The name of the dataset to run (\"squad\", \"pubmed\", \"arxiv\").\n",
        "        sample_size (int): Number of samples to use from the dataset.\n",
        "        k (int): Number of top documents to retrieve.\n",
        "\n",
        "    Returns:\n",
        "        None: Prints evaluation metrics for the specified dataset.\n",
        "    \"\"\"\n",
        "    if dataset_name == \"squad\":\n",
        "        # Load and evaluate SQuAD dataset\n",
        "        print(\"Loading SQuAD dataset...\")\n",
        "        squad_path = \"squad/train-v2.0.json\"\n",
        "        documents_squad, queries_squad, relevant_docs_squad = load_squad_data(squad_path)\n",
        "        retrieval_pool, queries_subset, relevant_docs_subset = reduce_dataset(\n",
        "            documents_squad, queries_squad, relevant_docs_squad, sample_size=sample_size, dataset_name=\"squad\"\n",
        "        )\n",
        "        print(f\"Running SQuAD benchmark with {sample_size} samples and k={k}...\")\n",
        "        metrics_squad = evaluate_retrievers(retrieval_pool, queries_subset, relevant_docs_subset, k=k)\n",
        "        print(\"\\nBenchmark Results for SQuAD:\")\n",
        "        for retriever_name, retriever_metrics in metrics_squad.items():\n",
        "            print(f\"  {retriever_name}:\")\n",
        "            for metric, value in retriever_metrics.items():\n",
        "                print(f\"    {metric}: {value:.4f}\")\n",
        "\n",
        "    elif dataset_name == \"pubmed\":\n",
        "        # Load and evaluate PubMedQA dataset\n",
        "        print(\"Loading PubMedQA dataset...\")\n",
        "        pubmedqa_path = \"pubmedqa/ori_pqal.json\"\n",
        "        documents_pubmedqa, queries_pubmedqa, relevant_docs_pubmedqa = load_pubmedqa_data(pubmedqa_path)\n",
        "        retrieval_pool, queries_subset, relevant_docs_subset = reduce_dataset(\n",
        "            documents_pubmedqa, queries_pubmedqa, relevant_docs_pubmedqa, sample_size=sample_size, dataset_name=\"pubmed\"\n",
        "        )\n",
        "        print(f\"Running PubMedQA benchmark with {sample_size} samples and k={k}...\")\n",
        "        metrics_pubmedqa = evaluate_retrievers(retrieval_pool, queries_subset, relevant_docs_subset, k=k)\n",
        "        print(\"\\nBenchmark Results for PubMedQA:\")\n",
        "        for retriever_name, retriever_metrics in metrics_pubmedqa.items():\n",
        "            print(f\"  {retriever_name}:\")\n",
        "            for metric, value in retriever_metrics.items():\n",
        "                print(f\"    {metric}: {value:.4f}\")\n",
        "\n",
        "    elif dataset_name == \"arxiv\":\n",
        "        # Load and evaluate arXiv dataset\n",
        "        print(\"Loading arXiv dataset...\")\n",
        "        arxiv_path = \"/content/arxiv/arxiv-metadata-subset.json\"\n",
        "        documents, queries, relevant_docs = load_arxiv_data(arxiv_path)\n",
        "        reduced_documents, reduced_queries, reduced_relevant_docs = reduce_dataset(\n",
        "            documents, queries, relevant_docs, sample_size=sample_size, dataset_name=\"arxiv\"\n",
        "        )\n",
        "        print(f\"Running arXiv benchmark with {sample_size} samples and k={k}...\")\n",
        "        metrics_arxiv = evaluate_retrievers(reduced_documents, reduced_queries, reduced_relevant_docs, k=k)\n",
        "        print(\"\\nBenchmark Results for arXiv:\")\n",
        "        for retriever_name, retriever_metrics in metrics_arxiv.items():\n",
        "            print(f\"  {retriever_name}:\")\n",
        "            for metric, value in retriever_metrics.items():\n",
        "                print(f\"    {metric}: {value:.4f}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Error: Unsupported dataset '{dataset_name}'. Please choose 'squad', 'pubmed', or 'arxiv'.\")\n"
      ],
      "metadata": {
        "id": "3TbphHJet6Lu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_benchmarks_single(dataset_name=\"pubmed\", sample_size=20000, k=7)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXJMpjaNt6JG",
        "outputId": "09d2924e-3665-423e-ebb6-777d8ff454bc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading PubMedQA dataset...\n",
            "Documents: 2000, Queries: 1000, Relevant Docs: 1000\n",
            "Running PubMedQA benchmark with 20000 samples and k=7...\n",
            "Encoding documents...\n",
            "Building graph...\n",
            "Detecting communities...\n",
            "Graph constructed with density: 0.0035, 1 connected components, and 24 communities.\n",
            "\n",
            "Benchmark Results for PubMedQA:\n",
            "  BaseRAG:\n",
            "    hits: 0.9060\n",
            "    mrr: 0.6437\n",
            "    precision: 0.1294\n",
            "    recall: 0.9060\n",
            "    avg_time: 0.0144\n",
            "  GraphRAG:\n",
            "    hits: 0.9120\n",
            "    mrr: 0.6441\n",
            "    precision: 0.1303\n",
            "    recall: 0.9120\n",
            "    avg_time: 0.0571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jdy-b8rKuLJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZuDodq3LuLGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Svc5wVyuLD3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
